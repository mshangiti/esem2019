topics[which(topics$topicName=="NLP"),"plotorder"] = 1
topics[which(topics$topicName=="TF_debugging"),"plotorder"] = 2
topics[which(topics$topicName=="Evaluation_Classification"),"plotorder"] = 3
topics[which(topics$topicName=="Convergence_Determination"),"plotorder"] = 4
topics[which(topics$topicName=="Visualization"),"plotorder"] = 5
topics[which(topics$topicName=="Decision_Tree"),"plotorder"] = 6
topics[which(topics$topicName=="Optimization"),"plotorder"] = 8
topics[which(topics$topicName=="keras"),"plotorder"] = 7
topics[which(topics$topicName=="Clustering"),"plotorder"] = 10
topics[which(topics$topicName=="Neural_Networks"),"plotorder"] = 11
topics[which(topics$topicName=="Data_Prep"),"plotorder"] = 12
topics[which(topics$topicName=="Evaluation_Regression"),"plotorder"] = 13
topics[which(topics$topicName=="Feature_Preprocessing"),"plotorder"] = 14
topics[which(topics$topicName=="Environment_Setup"),"plotorder"] = 19
topics[which(topics$topicName=="Data_Prep2"),"plotorder"] = 20
topics[which(topics$topicName=="Preprocessing_images"),"plotorder"] = 21
topics[which(topics$topicName=="Object_Detection"),"plotorder"] = 22
topics[which(topics$topicName=="Applied_NN"),"plotorder"] = 23
topics[which(topics$topicName=="Model_Training"),"plotorder"] = 24
topics[which(topics$topicName=="TF_hardware"),"plotorder"] = 25
topics[which(topics$topicName=="TF_Installation"),"plotorder"] = 26
topics[which(topics$topicName=="TF_graph"),"plotorder"] = 30
topics[which(topics$topicName=="TF_prog_err"),"plotorder"] = 29
topics[which(topics$topicName=="Model_Saving"),"plotorder"] = 28
topics[which(topics$topicName=="Deployment"),"plotorder"] = 27
myplot = ggplot(data=topics, aes(x= reorder(topicWords,plotorder)   , y = postCount, fill=topicClass))+
#myplot = ggplot(data=topics[-c(19),], aes(x=topicName, y = viewsCount, fill=topicName))+
#geom_bar(fill = "#4589c6", color="black",stat="identity")+
# geom_bar(stat="identity",color="black")+   scale_fill_manual(values = c(rgb(0.549,0.980,0.553),rgb(0.988,0.729,0.714),rgb(0.498,0.875,0.882))) +
#geom_bar(stat="identity",color="black")+   scale_fill_manual(values = c(rgb(0.216,0.208,0.220),rgb(0.894,0.882,0.894),rgb(0.655,0.643,0.659))) +
geom_bar(stat="identity",colour = "black")+scale_fill_brewer(palette="Oranges")+
#
geom_label(aes(label =topicName,fontface=2),position = position_stack(vjust = 1),size =5.5,fill = 'white', colour = 'black')+
#geom_histogram(stat="identity")+
#geom_line(col=rgb(0.1,0.7,0.1,0.8), lwd=2 ) + geom_point( pch=20 , cex=8) +
#geom_point(data=temp[3,], aes(x=K, y=Coherence), colour="#008ECC", size=10) +
labs(title="", x="Three-word Topics",y="#Questions") +
theme_bw() +theme(panel.grid.major = element_blank())+
theme(legend.title=element_blank())+ theme(legend.position="top") + theme(legend.key.width=unit(1.5,"cm")) +
theme(legend.spacing.x = unit(0.5,"cm"), legend.text = element_text(size=20, face = "bold", color = "black") ) +
theme(text = element_text(size=30), axis.text.x = element_text(size=20,face = "bold"), axis.text.y = element_text(size=35))+
theme(axis.text.x = element_text(angle = 30, hjust = 1))
#geom_label() + theme(axis.text.x = element_text(angle = 30, hjust = 1))
#geom_text(aes(x = topicName, y = viewsCount, label=topicWords), angle = 90) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
myplot
p=ggplot(topics, aes(x=unanswered_topic, y=viewsCount, color=unanswered_topic_factor, label=topicName)) +
geom_point() +    geom_label(aes(label =topicName,fontface=2),position = position_stack(vjust = 1),size =8,fill = 'white', colour = 'black') + xlim(0.52,0.68) + labs(title="", x="Difficulty (% no accepted answer)",y="Popularity (% views)") +
geom_hline(aes(yintercept = 0.050)) + geom_vline(aes(xintercept = 0.60)) +
theme(panel.background = element_blank())+
theme(legend.position="none") +
theme(text = element_text(size=30,face = "bold"), axis.text.x = element_text(size=30,face = "bold"), axis.text.y = element_text(size=30,face = "bold"))
p
library(ggplot2)
library(ggExtra)
p=ggplot(topics, aes(x=unanswered_topic, y=viewsCount, color=unanswered_topic_factor, label=topicName)) +
geom_point() +    geom_label(aes(label =topicName,fontface=2),position = position_stack(vjust = 1),size =8,fill = 'white', colour = 'black') + xlim(0.52,0.68) + labs(title="", x="Difficulty (% no accepted answer)",y="Popularity (% views)") +
geom_hline(aes(yintercept = 0.050)) + geom_vline(aes(xintercept = 0.60)) +
theme(panel.background = element_blank())+
theme(legend.position="none") +
theme(text = element_text(size=30,face = "bold"), axis.text.x = element_text(size=30,face = "bold"), axis.text.y = element_text(size=30,face = "bold"))
p
topics[,"unanswered_topic_factor"] = "Low % Unanswered Questions (< Median)"
topics[which(topics$unanswered_topic>median(topics$unanswered_topic)),"unanswered_topic_factor"] = "High % Unanswered Questions (> Median)"
p=ggplot(topics, aes(x=unanswered_topic, y=viewsCount, color=unanswered_topic_factor, label=topicName)) +
geom_point() +    geom_label(aes(label =topicName,fontface=2),position = position_stack(vjust = 1),size =8,fill = 'white', colour = 'black') + xlim(0.52,0.68) + labs(title="", x="Difficulty (% no accepted answer)",y="Popularity (% views)") +
geom_hline(aes(yintercept = 0.050)) + geom_vline(aes(xintercept = 0.60)) +
theme(panel.background = element_blank())+
theme(legend.position="none") +
theme(text = element_text(size=30,face = "bold"), axis.text.x = element_text(size=30,face = "bold"), axis.text.y = element_text(size=30,face = "bold"))
p
setwd("~/Dropbox/Development/University Dev/Classes/RIT/research/esem2019")
ldamat=read.csv("./custom/ml_lda_gensim_mat.txt",header=F)
ldaterms=read.csv("./custom/ml_lda_gensim_term.txt",header=F)
resultset = rbind(read.csv2("./quantitative_sample/ml_quan_sample_1.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_2.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_3.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_4.csv", stringsAsFactors=FALSE))
#creating a year column
resultset[,"year"] = as.numeric(format(as.POSIXlt(resultset[,"CreationDate"]),"%Y"))
#finding dominant topic
resultset$dominatingTopic = "NA"
for(i in 1:dim(ldamat)[1]){
print(i)
#maxtopic = c(maxtopic,as.numeric(sort(lda[i,],decreasing = T)[1]))
#maxtopic2 = c(maxtopic2,as.numeric(sort(lda[i,],decreasing = T)[2]))
resultset[i,"dominatingTopic"] = names(sort(ldamat[i,],decreasing = T)[1])
resultset[i,"dominatingProb"] = as.numeric(sort(ldamat[i,],decreasing = T)[1])
}
resultset[which(resultset$dominatingTopic=="V15"),"dominatingTopic"] = "V14"
temp = resultset
topicId = c("V8","V11","V19","V10","V30")
for(i in 1:length(topicId)){
print(paste("Working on topic", i))
#generating list of question posts that fall under current topic
questionlist = which(resultset$dominatingTopic==topicId[i])
#looping over question posts
for (j in 1:length(questionlist)){
myid = questionlist[j]
newtopicid=2
while(names(sort(ldamat[myid,],decreasing = T)[newtopicid]) %in% topicId){
newtopicid = newtopicid + 1
}
resultset[myid,"dominatingTopic"] = names(sort(ldamat[myid,],decreasing = T)[newtopicid])
resultset[myid,"dominatingProb"] = as.numeric(sort(ldamat[myid,],decreasing = T)[newtopicid])
}
}
table(resultset$dominatingTopic)
names(sort(ldamat[myid,],decreasing = T)
)
names(sort(ldamat[myid,],decreasing = T)[newtopicid]) %in% topicId
names(sort(ldamat[myid,],decreasing = T)[1])
names(sort(ldamat[myid,],decreasing = T)[2])
names(sort(ldamat[myid,],decreasing = T)[3])
View(ldamat)
topiclist = mixedsort(unique(resultset$dominatingTopic))
topiclist
topiclist = mixedsort(unique(resultset$dominatingTopic))
k = length(topiclist)
topics = data.frame(topicId=as.factor(topiclist),topicName=(rep(0,k)),topicWords=(rep(0,k)),topicTags=(rep(0,k)), postCount=(rep(0,k)),viewsCount=(rep(0,k)),scoreCount=(rep(0,k)),commentCount=(rep(0,k)),naaCount=(rep(0,k)),responseTime=(rep(0,k)))
topics
topics[which(topics$topicId=="V1"),c("topicName", "topicWords", "topicTags")] = c("Neural_Networks", "weight,layer,neural_network","neural-network,multi-layer,backpropagation")#excellent
topics[which(topics$topicId=="V2"),c("topicName", "topicWords", "topicTags")] = c("Applied_NN", "input,output,tensor,batch","tensorflow,neural-network,rnn")#fair
topics[which(topics$topicId=="V3"),c("topicName", "topicWords", "topicTags")] = c("Decision_Tree", "tree,leaf,node","parsing,IR,decision-tree,classification")#fair
topics[which(topics$topicId=="V4"),c("topicName", "topicWords", "topicTags")] = c("Visualization", "line,plot,point","tensorboard,ggplot2,boxplot,matlab")#fair
topics[which(topics$topicId=="V5"),c("topicName", "topicWords", "topicTags")] = c("Optimization", "gradient,cost,theta","gradient-descent,cost-based-optimizer,neural-network")
topics[which(topics$topicId=="V6"),c("topicName", "topicWords", "topicTags")] = c("TF_Installation", "tensorflow,error,install","tensorflow,pip,installation")
topics[which(topics$topicId=="V7"),c("topicName", "topicWords", "topicTags")] = c("Environment_Setup", "import,recent_call,return_self","scikit-learn,anaconda")
#topic 8 is out
topics[which(topics$topicId=="V9"),c("topicName", "topicWords", "topicTags")] = c("TF_graph", "tf,graph,graph_def","tensorflow,python") #low dominance
#topic 10 is out
#topic 11 is out
topics[which(topics$topicId=="V12"),c("topicName", "topicWords", "topicTags")] = c("Convergence_Determination", "train_accuraci,loss,learn_rate","softmax,covergence,nn")
topics[which(topics$topicId=="V13"),c("topicName", "topicWords", "topicTags")] = c("Deployment", "user,product,api","google-prediction,azure,api,web-services,firebase")
topics[which(topics$topicId=="V14"),c("topicName", "topicWords", "topicTags")] = c("Data_Prep", "nan,label,format","data-management,aggregation,input")
#topic 15 is out
topics[which(topics$topicId=="V16"),c("topicName", "topicWords", "topicTags")] = c("TF_debugging", "tf,sess_run,tf_variabl","tensorflow,iterable,tensor")
topics[which(topics$topicId=="V17"),c("topicName", "topicWords", "topicTags")] = c("TF_prog_err", "py_line,packag_tensorflow,run","tensorflow,django,ubuntu,low-memory,seq-to-seq")
topics[which(topics$topicId=="V18"),c("topicName", "topicWords", "topicTags")] = c("Model_Saving", "model,load,save","tensorflow-serving,google-cloud-functions")
# topic 19 is out
topics[which(topics$topicId=="V20"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Classification", "class,accuraci,confus_matrix","classification,precision-recall,analytics,predictive")
topics[which(topics$topicId=="V21"),c("topicName", "topicWords", "topicTags")] = c("Object_Detection", "object_detect,face,bound_box","image-segmentation,object-detection,opencv,image-processing,motion-detection,tracking,feature-extraction")
topics[which(topics$topicId=="V22"),c("topicName", "topicWords", "topicTags")] = c("Feature_Preprocessing", "featur,transform,split","pandas,feature-extraction,feature-selection")
topics[which(topics$topicId=="V23"),c("topicName", "topicWords", "topicTags")] = c("Model_Training", "train,sampl,fit","cross-validation,validation,gradient-descent")
topics[which(topics$topicId=="V24"),c("topicName", "topicWords", "topicTags")] = c("keras", "kera,model,input_shape","keras,conv-neural-network,deep-learning,neural-networks")
topics[which(topics$topicId=="V25"),c("topicName", "topicWords", "topicTags")] = c("Clustering", "cluster,distanc,,centroid","hierarchical-clustering,cluster-analysis,kmeans")
topics[which(topics$topicId=="V26"),c("topicName", "topicWords", "topicTags")] = c("TF_hardware", "tensorflow,gpu,cpu","multithreading,gpu,gensorflow-gpu")
topics[which(topics$topicId=="V27"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Regression", "regress,error,auc","lasso,linear-regression,glmnet,interpretation")
topics[which(topics$topicId=="V28"),c("topicName", "topicWords", "topicTags")] = c("NLP", "text,tweet,,senti","nlp,classification,stanford-nlp,opennlp")
topics[which(topics$topicId=="V29"),c("topicName", "topicWords", "topicTags")] = c("Preprocessing_images", "img,mask,convert","pickle,cnn,feature-extration,unit,image-processing")
#topic 30 is out
topics = data.frame(topicId=as.factor(topiclist),topicName=(rep(0,k)),topicWords=(rep(0,k)), postCount=(rep(0,k)),viewsCount=(rep(0,k)),naaCount=(rep(0,k)))
#filling placeholder with data
topics
topics = data.frame(topicId=as.factor(topiclist),topicName=(rep(0,k)),topicWords=(rep(0,k)),topicTags=(rep(0,k)), postCount=(rep(0,k)),viewsCount=(rep(0,k)),naaCount=(rep(0,k)))
#filling placeholder with data
topics[which(topics$topicId=="V1"),c("topicName", "topicWords", "topicTags")] = c("Neural_Networks", "weight,layer,neural_network","neural-network,multi-layer,backpropagation")#excellent
topics[which(topics$topicId=="V2"),c("topicName", "topicWords", "topicTags")] = c("Applied_NN", "input,output,tensor,batch","tensorflow,neural-network,rnn")#fair
topics[which(topics$topicId=="V3"),c("topicName", "topicWords", "topicTags")] = c("Decision_Tree", "tree,leaf,node","parsing,IR,decision-tree,classification")#fair
topics[which(topics$topicId=="V4"),c("topicName", "topicWords", "topicTags")] = c("Visualization", "line,plot,point","tensorboard,ggplot2,boxplot,matlab")#fair
topics[which(topics$topicId=="V5"),c("topicName", "topicWords", "topicTags")] = c("Optimization", "gradient,cost,theta","gradient-descent,cost-based-optimizer,neural-network")
topics[which(topics$topicId=="V6"),c("topicName", "topicWords", "topicTags")] = c("TF_Installation", "tensorflow,error,install","tensorflow,pip,installation")
topics[which(topics$topicId=="V7"),c("topicName", "topicWords", "topicTags")] = c("Environment_Setup", "import,recent_call,return_self","scikit-learn,anaconda")
#topic 8 is out
topics[which(topics$topicId=="V9"),c("topicName", "topicWords", "topicTags")] = c("TF_graph", "tf,graph,graph_def","tensorflow,python") #low dominance
#topic 10 is out
#topic 11 is out
topics[which(topics$topicId=="V12"),c("topicName", "topicWords", "topicTags")] = c("Convergence_Determination", "train_accuraci,loss,learn_rate","softmax,covergence,nn")
topics[which(topics$topicId=="V13"),c("topicName", "topicWords", "topicTags")] = c("Deployment", "user,product,api","google-prediction,azure,api,web-services,firebase")
topics[which(topics$topicId=="V14"),c("topicName", "topicWords", "topicTags")] = c("Data_Prep", "nan,label,format","data-management,aggregation,input")
#topic 15 is out
topics[which(topics$topicId=="V16"),c("topicName", "topicWords", "topicTags")] = c("TF_debugging", "tf,sess_run,tf_variabl","tensorflow,iterable,tensor")
topics[which(topics$topicId=="V17"),c("topicName", "topicWords", "topicTags")] = c("TF_prog_err", "py_line,packag_tensorflow,run","tensorflow,django,ubuntu,low-memory,seq-to-seq")
topics[which(topics$topicId=="V18"),c("topicName", "topicWords", "topicTags")] = c("Model_Saving", "model,load,save","tensorflow-serving,google-cloud-functions")
# topic 19 is out
topics[which(topics$topicId=="V20"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Classification", "class,accuraci,confus_matrix","classification,precision-recall,analytics,predictive")
topics[which(topics$topicId=="V21"),c("topicName", "topicWords", "topicTags")] = c("Object_Detection", "object_detect,face,bound_box","image-segmentation,object-detection,opencv,image-processing,motion-detection,tracking,feature-extraction")
topics[which(topics$topicId=="V22"),c("topicName", "topicWords", "topicTags")] = c("Feature_Preprocessing", "featur,transform,split","pandas,feature-extraction,feature-selection")
topics[which(topics$topicId=="V23"),c("topicName", "topicWords", "topicTags")] = c("Model_Training", "train,sampl,fit","cross-validation,validation,gradient-descent")
topics[which(topics$topicId=="V24"),c("topicName", "topicWords", "topicTags")] = c("keras", "kera,model,input_shape","keras,conv-neural-network,deep-learning,neural-networks")
topics[which(topics$topicId=="V25"),c("topicName", "topicWords", "topicTags")] = c("Clustering", "cluster,distanc,,centroid","hierarchical-clustering,cluster-analysis,kmeans")
topics[which(topics$topicId=="V26"),c("topicName", "topicWords", "topicTags")] = c("TF_hardware", "tensorflow,gpu,cpu","multithreading,gpu,gensorflow-gpu")
topics[which(topics$topicId=="V27"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Regression", "regress,error,auc","lasso,linear-regression,glmnet,interpretation")
topics[which(topics$topicId=="V28"),c("topicName", "topicWords", "topicTags")] = c("NLP", "text,tweet,,senti","nlp,classification,stanford-nlp,opennlp")
topics[which(topics$topicId=="V29"),c("topicName", "topicWords", "topicTags")] = c("Preprocessing_images", "img,mask,convert","pickle,cnn,feature-extration,unit,image-processing")
#topic 30 is out
topics[which(topics$topicId=="V4" | topics$topicId=="V6" | topics$topicId=="V7" | topics$topicId=="V9"|
topics$topicId=="V13"|topics$topicId=="V14"|topics$topicId=="V15"|topics$topicId=="V16"| topics$topicId=="V2" |
topics$topicId=="V17" | topics$topicId=="V18" | topics$topicId=="V22" | topics$topicId=="V26" | topics$topicId=="V29" | topics$topicId=="V24"),"topicClass"]  = "ML Library"
topics[which(topics$topicId=="V5" | topics$topicId=="V12" | topics$topicId=="V20" | topics$topicId=="V21" | topics$topicId=="V23"| topics$topicId=="V27"|topics$topicId=="V28"),"topicClass"]  = "ML Concept"
topics[which(topics$topicId=="V1" | topics$topicId=="V3" | topics$topicId=="V25"),"topicClass"]  = "ML Algorithm"
for(i in 1:length(topiclist)){
topics[which(topics$topicId==topiclist[i]),"postCount"] = length(which(resultset$dominatingTopic==topiclist[i]))
topics[which(topics$topicId==topiclist[i]),"viewsCount"] = sum(resultset[which(resultset$dominatingTopic==topiclist[i]),c("ViewCount")])/sum(resultset[,c("ViewCount")])
#topics[which(topics$topicId==topiclist[i]),"unanswered_all"] = length(resultset[which(resultset$dominatingTopic==topiclist[i] & resultset$AcceptedAnswerId=="None"),c("AcceptedAnswerId")]) / length(resultset[which(resultset$AcceptedAnswerId=="None"),c("AcceptedAnswerId")])
topics[which(topics$topicId==topiclist[i]),"unanswered_topic"] = length(resultset[which(resultset$dominatingTopic==topiclist[i] & resultset$AcceptedAnswerId=="None"),c("AcceptedAnswerId")]) /length(resultset[which(resultset$dominatingTopic==topiclist[i]),c("AcceptedAnswerId")])
}
topics[,"unanswered_topic_factor"] = "Low % Unanswered Questions (< Median)"
topics[which(topics$unanswered_topic>median(topics$unanswered_topic)),"unanswered_topic_factor"] = "High % Unanswered Questions (> Median)"
topics = topics[order(topics$unanswered_topic),]
topics[,"plotorder"] = 1:k
topics[which(topics$topicName=="NLP"),"plotorder"] = 1
topics[which(topics$topicName=="TF_debugging"),"plotorder"] = 2
topics[which(topics$topicName=="Evaluation_Classification"),"plotorder"] = 3
topics[which(topics$topicName=="Convergence_Determination"),"plotorder"] = 4
topics[which(topics$topicName=="Visualization"),"plotorder"] = 5
topics[which(topics$topicName=="Decision_Tree"),"plotorder"] = 6
topics[which(topics$topicName=="Optimization"),"plotorder"] = 8
topics[which(topics$topicName=="keras"),"plotorder"] = 7
topics[which(topics$topicName=="Clustering"),"plotorder"] = 10
topics[which(topics$topicName=="Neural_Networks"),"plotorder"] = 11
topics[which(topics$topicName=="Data_Prep"),"plotorder"] = 12
topics[which(topics$topicName=="Evaluation_Regression"),"plotorder"] = 13
topics[which(topics$topicName=="Feature_Preprocessing"),"plotorder"] = 14
topics[which(topics$topicName=="Environment_Setup"),"plotorder"] = 19
topics[which(topics$topicName=="Data_Prep2"),"plotorder"] = 20
topics[which(topics$topicName=="Preprocessing_images"),"plotorder"] = 21
topics[which(topics$topicName=="Object_Detection"),"plotorder"] = 22
topics[which(topics$topicName=="Applied_NN"),"plotorder"] = 23
topics[which(topics$topicName=="Model_Training"),"plotorder"] = 24
topics[which(topics$topicName=="TF_hardware"),"plotorder"] = 25
topics[which(topics$topicName=="TF_Installation"),"plotorder"] = 26
topics[which(topics$topicName=="TF_graph"),"plotorder"] = 30
topics[which(topics$topicName=="TF_prog_err"),"plotorder"] = 29
topics[which(topics$topicName=="Model_Saving"),"plotorder"] = 28
topics[which(topics$topicName=="Deployment"),"plotorder"] = 27
myplot = ggplot(data=topics, aes(x= reorder(topicWords,plotorder)   , y = postCount, fill=topicClass))+
#myplot = ggplot(data=topics[-c(19),], aes(x=topicName, y = viewsCount, fill=topicName))+
#geom_bar(fill = "#4589c6", color="black",stat="identity")+
# geom_bar(stat="identity",color="black")+   scale_fill_manual(values = c(rgb(0.549,0.980,0.553),rgb(0.988,0.729,0.714),rgb(0.498,0.875,0.882))) +
#geom_bar(stat="identity",color="black")+   scale_fill_manual(values = c(rgb(0.216,0.208,0.220),rgb(0.894,0.882,0.894),rgb(0.655,0.643,0.659))) +
geom_bar(stat="identity",colour = "black")+scale_fill_brewer(palette="Oranges")+
#
geom_label(aes(label =topicName,fontface=2),position = position_stack(vjust = 1),size =5.5,fill = 'white', colour = 'black')+
#geom_histogram(stat="identity")+
#geom_line(col=rgb(0.1,0.7,0.1,0.8), lwd=2 ) + geom_point( pch=20 , cex=8) +
#geom_point(data=temp[3,], aes(x=K, y=Coherence), colour="#008ECC", size=10) +
labs(title="", x="Three-word Topics",y="#Questions") +
theme_bw() +theme(panel.grid.major = element_blank())+
theme(legend.title=element_blank())+ theme(legend.position="top") + theme(legend.key.width=unit(1.5,"cm")) +
theme(legend.spacing.x = unit(0.5,"cm"), legend.text = element_text(size=20, face = "bold", color = "black") ) +
theme(text = element_text(size=30), axis.text.x = element_text(size=20,face = "bold"), axis.text.y = element_text(size=35))+
theme(axis.text.x = element_text(angle = 30, hjust = 1))
#geom_label() + theme(axis.text.x = element_text(angle = 30, hjust = 1))
#geom_text(aes(x = topicName, y = viewsCount, label=topicWords), angle = 90) + theme(axis.text.x = element_text(angle = 45, hjust = 1))
myplot
topics
p=ggplot(topics, aes(x=unanswered_topic, y=viewsCount, color=unanswered_topic_factor, label=topicName)) +
geom_point() +    geom_label(aes(label =topicName,fontface=2),position = position_stack(vjust = 1),size =8,fill = 'white', colour = 'black') + xlim(0.52,0.68) + labs(title="", x="Difficulty (% no accepted answer)",y="Popularity (% views)") +
geom_hline(aes(yintercept = 0.050)) + geom_vline(aes(xintercept = 0.60)) +
theme(panel.background = element_blank())+
theme(legend.position="none") +
theme(text = element_text(size=30,face = "bold"), axis.text.x = element_text(size=30,face = "bold"), axis.text.y = element_text(size=30,face = "bold"))
p
topics = data.frame(topicId=as.factor(topiclist),topicName=(rep(0,k)),topicWords=(rep(0,k)),topicTags=(rep(0,k)), postCount=(rep(0,k)),viewsCount=(rep(0,k)))
topics[which(topics$topicId=="V1"),c("topicName", "topicWords", "topicTags")] = c("Neural_Networks", "weight,layer,neural_network","neural-network,multi-layer,backpropagation")#excellent
topics[which(topics$topicId=="V2"),c("topicName", "topicWords", "topicTags")] = c("Applied_NN", "input,output,tensor,batch","tensorflow,neural-network,rnn")#fair
topics[which(topics$topicId=="V3"),c("topicName", "topicWords", "topicTags")] = c("Decision_Tree", "tree,leaf,node","parsing,IR,decision-tree,classification")#fair
topics[which(topics$topicId=="V4"),c("topicName", "topicWords", "topicTags")] = c("Visualization", "line,plot,point","tensorboard,ggplot2,boxplot,matlab")#fair
topics[which(topics$topicId=="V5"),c("topicName", "topicWords", "topicTags")] = c("Optimization", "gradient,cost,theta","gradient-descent,cost-based-optimizer,neural-network")
topics[which(topics$topicId=="V6"),c("topicName", "topicWords", "topicTags")] = c("TF_Installation", "tensorflow,error,install","tensorflow,pip,installation")
topics[which(topics$topicId=="V7"),c("topicName", "topicWords", "topicTags")] = c("Environment_Setup", "import,recent_call,return_self","scikit-learn,anaconda")
#topic 8 is out
topics[which(topics$topicId=="V9"),c("topicName", "topicWords", "topicTags")] = c("TF_graph", "tf,graph,graph_def","tensorflow,python") #low dominance
#topic 10 is out
#topic 11 is out
topics[which(topics$topicId=="V12"),c("topicName", "topicWords", "topicTags")] = c("Convergence_Determination", "train_accuraci,loss,learn_rate","softmax,covergence,nn")
topics[which(topics$topicId=="V13"),c("topicName", "topicWords", "topicTags")] = c("Deployment", "user,product,api","google-prediction,azure,api,web-services,firebase")
topics[which(topics$topicId=="V14"),c("topicName", "topicWords", "topicTags")] = c("Data_Prep", "nan,label,format","data-management,aggregation,input")
#topic 15 is out
topics[which(topics$topicId=="V16"),c("topicName", "topicWords", "topicTags")] = c("TF_debugging", "tf,sess_run,tf_variabl","tensorflow,iterable,tensor")
topics[which(topics$topicId=="V17"),c("topicName", "topicWords", "topicTags")] = c("TF_prog_err", "py_line,packag_tensorflow,run","tensorflow,django,ubuntu,low-memory,seq-to-seq")
topics[which(topics$topicId=="V18"),c("topicName", "topicWords", "topicTags")] = c("Model_Saving", "model,load,save","tensorflow-serving,google-cloud-functions")
# topic 19 is out
topics[which(topics$topicId=="V20"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Classification", "class,accuraci,confus_matrix","classification,precision-recall,analytics,predictive")
topics[which(topics$topicId=="V21"),c("topicName", "topicWords", "topicTags")] = c("Object_Detection", "object_detect,face,bound_box","image-segmentation,object-detection,opencv,image-processing,motion-detection,tracking,feature-extraction")
topics[which(topics$topicId=="V22"),c("topicName", "topicWords", "topicTags")] = c("Feature_Preprocessing", "featur,transform,split","pandas,feature-extraction,feature-selection")
topics[which(topics$topicId=="V23"),c("topicName", "topicWords", "topicTags")] = c("Model_Training", "train,sampl,fit","cross-validation,validation,gradient-descent")
topics[which(topics$topicId=="V24"),c("topicName", "topicWords", "topicTags")] = c("keras", "kera,model,input_shape","keras,conv-neural-network,deep-learning,neural-networks")
topics[which(topics$topicId=="V25"),c("topicName", "topicWords", "topicTags")] = c("Clustering", "cluster,distanc,,centroid","hierarchical-clustering,cluster-analysis,kmeans")
topics[which(topics$topicId=="V26"),c("topicName", "topicWords", "topicTags")] = c("TF_hardware", "tensorflow,gpu,cpu","multithreading,gpu,gensorflow-gpu")
topics[which(topics$topicId=="V27"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Regression", "regress,error,auc","lasso,linear-regression,glmnet,interpretation")
topics[which(topics$topicId=="V28"),c("topicName", "topicWords", "topicTags")] = c("NLP", "text,tweet,,senti","nlp,classification,stanford-nlp,opennlp")
topics[which(topics$topicId=="V29"),c("topicName", "topicWords", "topicTags")] = c("Preprocessing_images", "img,mask,convert","pickle,cnn,feature-extration,unit,image-processing")
#topic 30 is out
topics = data.frame(topicId=as.factor(topiclist),topicName=(rep(0,k)),topicWords=(rep(0,k)),topicTags=(rep(0,k)), postCount=(rep(0,k)),viewsCount=(rep(0,k)))
#
#assigning topic names, words, and tags
topics[which(topics$topicId=="V1"),c("topicName", "topicWords", "topicTags")] = c("Neural_Networks", "weight,layer,neural_network","neural-network,multi-layer,backpropagation")#excellent
topics[which(topics$topicId=="V2"),c("topicName", "topicWords", "topicTags")] = c("Applied_NN", "input,output,tensor,batch","tensorflow,neural-network,rnn")#fair
topics[which(topics$topicId=="V3"),c("topicName", "topicWords", "topicTags")] = c("Decision_Tree", "tree,leaf,node","parsing,IR,decision-tree,classification")#fair
topics[which(topics$topicId=="V4"),c("topicName", "topicWords", "topicTags")] = c("Visualization", "line,plot,point","tensorboard,ggplot2,boxplot,matlab")#fair
topics[which(topics$topicId=="V5"),c("topicName", "topicWords", "topicTags")] = c("Optimization", "gradient,cost,theta","gradient-descent,cost-based-optimizer,neural-network")
topics[which(topics$topicId=="V6"),c("topicName", "topicWords", "topicTags")] = c("TF_Installation", "tensorflow,error,install","tensorflow,pip,installation")
topics[which(topics$topicId=="V7"),c("topicName", "topicWords", "topicTags")] = c("Environment_Setup", "import,recent_call,return_self","scikit-learn,anaconda")
#topic 8 is out
topics[which(topics$topicId=="V9"),c("topicName", "topicWords", "topicTags")] = c("TF_graph", "tf,graph,graph_def","tensorflow,python") #low dominance
#topic 10 is out
#topic 11 is out
topics[which(topics$topicId=="V12"),c("topicName", "topicWords", "topicTags")] = c("Convergence_Determination", "train_accuraci,loss,learn_rate","softmax,covergence,nn")
topics[which(topics$topicId=="V13"),c("topicName", "topicWords", "topicTags")] = c("Deployment", "user,product,api","google-prediction,azure,api,web-services,firebase")
topics[which(topics$topicId=="V14"),c("topicName", "topicWords", "topicTags")] = c("Data_Prep", "nan,label,format","data-management,aggregation,input")
#topic 15 is out
topics[which(topics$topicId=="V16"),c("topicName", "topicWords", "topicTags")] = c("TF_debugging", "tf,sess_run,tf_variabl","tensorflow,iterable,tensor")
topics[which(topics$topicId=="V17"),c("topicName", "topicWords", "topicTags")] = c("TF_prog_err", "py_line,packag_tensorflow,run","tensorflow,django,ubuntu,low-memory,seq-to-seq")
topics[which(topics$topicId=="V18"),c("topicName", "topicWords", "topicTags")] = c("Model_Saving", "model,load,save","tensorflow-serving,google-cloud-functions")
# topic 19 is out
topics[which(topics$topicId=="V20"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Classification", "class,accuraci,confus_matrix","classification,precision-recall,analytics,predictive")
topics[which(topics$topicId=="V21"),c("topicName", "topicWords", "topicTags")] = c("Object_Detection", "object_detect,face,bound_box","image-segmentation,object-detection,opencv,image-processing,motion-detection,tracking,feature-extraction")
topics[which(topics$topicId=="V22"),c("topicName", "topicWords", "topicTags")] = c("Feature_Preprocessing", "featur,transform,split","pandas,feature-extraction,feature-selection")
topics[which(topics$topicId=="V23"),c("topicName", "topicWords", "topicTags")] = c("Model_Training", "train,sampl,fit","cross-validation,validation,gradient-descent")
topics[which(topics$topicId=="V24"),c("topicName", "topicWords", "topicTags")] = c("keras", "kera,model,input_shape","keras,conv-neural-network,deep-learning,neural-networks")
topics[which(topics$topicId=="V25"),c("topicName", "topicWords", "topicTags")] = c("Clustering", "cluster,distanc,,centroid","hierarchical-clustering,cluster-analysis,kmeans")
topics[which(topics$topicId=="V26"),c("topicName", "topicWords", "topicTags")] = c("TF_hardware", "tensorflow,gpu,cpu","multithreading,gpu,gensorflow-gpu")
topics[which(topics$topicId=="V27"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Regression", "regress,error,auc","lasso,linear-regression,glmnet,interpretation")
topics[which(topics$topicId=="V28"),c("topicName", "topicWords", "topicTags")] = c("NLP", "text,tweet,,senti","nlp,classification,stanford-nlp,opennlp")
topics[which(topics$topicId=="V29"),c("topicName", "topicWords", "topicTags")] = c("Preprocessing_images", "img,mask,convert","pickle,cnn,feature-extration,unit,image-processing")
#topic 30 is out
topics[which(topics$topicId=="V4" | topics$topicId=="V6" | topics$topicId=="V7" | topics$topicId=="V9"|
topics$topicId=="V13"|topics$topicId=="V14"|topics$topicId=="V15"|topics$topicId=="V16"| topics$topicId=="V2" |
topics$topicId=="V17" | topics$topicId=="V18" | topics$topicId=="V22" | topics$topicId=="V26" | topics$topicId=="V29" | topics$topicId=="V24"),"topicClass"]  = "ML Library"
topics[which(topics$topicId=="V5" | topics$topicId=="V12" | topics$topicId=="V20" | topics$topicId=="V21" | topics$topicId=="V23"| topics$topicId=="V27"|topics$topicId=="V28"),"topicClass"]  = "ML Concept"
topics[which(topics$topicId=="V1" | topics$topicId=="V3" | topics$topicId=="V25"),"topicClass"]  = "ML Algorithm"
topics
for(i in 1:length(topiclist)){
topics[which(topics$topicId==topiclist[i]),"postCount"] = length(which(resultset$dominatingTopic==topiclist[i]))
topics[which(topics$topicId==topiclist[i]),"viewsCount"] = sum(resultset[which(resultset$dominatingTopic==topiclist[i]),c("ViewCount")])/sum(resultset[,c("ViewCount")])
topics[which(topics$topicId==topiclist[i]),"unanswered_topic"] = length(resultset[which(resultset$dominatingTopic==topiclist[i] & resultset$AcceptedAnswerId=="None"),c("AcceptedAnswerId")]) /length(resultset[which(resultset$dominatingTopic==topiclist[i]),c("AcceptedAnswerId")])
}
topics
dim(topics)
topiclist
table(resultset$dominatingTopic)
##reading files
ldamat=read.csv("./custom/ml_lda_gensim_mat.txt",header=F)
ldaterms=read.csv("./custom/ml_lda_gensim_term.txt",header=F)
resultset = rbind(read.csv2("./quantitative_sample/ml_quan_sample_1.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_2.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_3.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_4.csv", stringsAsFactors=FALSE))
#creating a year column
resultset[,"year"] = as.numeric(format(as.POSIXlt(resultset[,"CreationDate"]),"%Y"))
#finding dominant topic
resultset$dominatingTopic = "NA"
for(i in 1:dim(ldamat)[1]){
print(i)
#maxtopic = c(maxtopic,as.numeric(sort(lda[i,],decreasing = T)[1]))
#maxtopic2 = c(maxtopic2,as.numeric(sort(lda[i,],decreasing = T)[2]))
resultset[i,"dominatingTopic"] = names(sort(ldamat[i,],decreasing = T)[1])
resultset[i,"dominatingProb"] = as.numeric(sort(ldamat[i,],decreasing = T)[1])
}
resultset[which(resultset$dominatingTopic=="V15"),"dominatingTopic"] = "V14"
table(resultset$dominatingTopic)
topicId = c("V8","V11","V19","V10","V30")
for(i in 1:length(topicId)){
print(paste("Working on topic", i))
#generating list of question posts that fall under current topic
questionlist = which(resultset$dominatingTopic==topicId[i])
#looping over question posts
for (j in 1:length(questionlist)){
#currrentquestion
myid = questionlist[j]
#finding the new dominating topic, starting with the 2nd topic with the highest prob.
#if it happens that 2nd topic is in our list of topicId, then more to the 3rd, etc.
newtopicid=2
while(names(sort(ldamat[myid,],decreasing = T)[newtopicid]) %in% topicId){
newtopicid = newtopicid + 1
}
resultset[myid,"dominatingTopic"] = names(sort(ldamat[myid,],decreasing = T)[newtopicid])
resultset[myid,"dominatingProb"] = as.numeric(sort(ldamat[myid,],decreasing = T)[newtopicid])
}
}
table(resultset$dominatingTopic)
##reading files
ldamat=read.csv("./custom/ml_lda_gensim_mat.txt",header=F)
ldaterms=read.csv("./custom/ml_lda_gensim_term.txt",header=F)
resultset = rbind(read.csv2("./quantitative_sample/ml_quan_sample_1.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_2.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_3.csv", stringsAsFactors=FALSE),
read.csv2("./quantitative_sample/ml_quan_sample_4.csv", stringsAsFactors=FALSE))
#creating a year column
resultset[,"year"] = as.numeric(format(as.POSIXlt(resultset[,"CreationDate"]),"%Y"))
##preprocessing required for plotting
#finding dominant topic
resultset$dominatingTopic = "NA"
for(i in 1:dim(ldamat)[1]){
print(i)
#maxtopic = c(maxtopic,as.numeric(sort(lda[i,],decreasing = T)[1]))
#maxtopic2 = c(maxtopic2,as.numeric(sort(lda[i,],decreasing = T)[2]))
resultset[i,"dominatingTopic"] = names(sort(ldamat[i,],decreasing = T)[1])
resultset[i,"dominatingProb"] = as.numeric(sort(ldamat[i,],decreasing = T)[1])
}
## Cleaning up topics
# 1. The following five noise topics (captures commonly used language in the corpus, i.e., ML related stop words)
#Solution: each question that falls under one of those topics will be assigned the 2nd most dominating topic
topicId = c("V8","V11","V19","V10","V30")
for(i in 1:length(topicId)){
print(paste("Working on topic", i))
#generating list of question posts that fall under current topic
questionlist = which(resultset$dominatingTopic==topicId[i])
#looping over question posts
for (j in 1:length(questionlist)){
#currrentquestion
myid = questionlist[j]
#finding the new dominating topic, starting with the 2nd topic with the highest prob.
#if it happens that 2nd topic is in our list of topicId, then more to the 3rd, etc.
newtopicid=2
while(names(sort(ldamat[myid,],decreasing = T)[newtopicid]) %in% topicId){
newtopicid = newtopicid + 1
}
resultset[myid,"dominatingTopic"] = names(sort(ldamat[myid,],decreasing = T)[newtopicid])
resultset[myid,"dominatingProb"] = as.numeric(sort(ldamat[myid,],decreasing = T)[newtopicid])
}
}
resultset[which(resultset$dominatingTopic=="V15"),"dominatingTopic"] = "V14"
table(resultset$dominatingTopic)
topiclist = mixedsort(unique(resultset$dominatingTopic))
k = length(topiclist)
topics = data.frame(topicId=as.factor(topiclist),topicName=(rep(0,k)),topicWords=(rep(0,k)),topicTags=(rep(0,k)), postCount=(rep(0,k)),viewsCount=(rep(0,k)))
dim(topics)
topics[which(topics$topicId=="V1"),c("topicName", "topicWords", "topicTags")] = c("Neural_Networks", "weight,layer,neural_network","neural-network,multi-layer,backpropagation")#excellent
topics[which(topics$topicId=="V2"),c("topicName", "topicWords", "topicTags")] = c("Applied_NN", "input,output,tensor,batch","tensorflow,neural-network,rnn")#fair
topics[which(topics$topicId=="V3"),c("topicName", "topicWords", "topicTags")] = c("Decision_Tree", "tree,leaf,node","parsing,IR,decision-tree,classification")#fair
topics[which(topics$topicId=="V4"),c("topicName", "topicWords", "topicTags")] = c("Visualization", "line,plot,point","tensorboard,ggplot2,boxplot,matlab")#fair
topics[which(topics$topicId=="V5"),c("topicName", "topicWords", "topicTags")] = c("Optimization", "gradient,cost,theta","gradient-descent,cost-based-optimizer,neural-network")
topics[which(topics$topicId=="V6"),c("topicName", "topicWords", "topicTags")] = c("TF_Installation", "tensorflow,error,install","tensorflow,pip,installation")
topics[which(topics$topicId=="V7"),c("topicName", "topicWords", "topicTags")] = c("Environment_Setup", "import,recent_call,return_self","scikit-learn,anaconda")
#topic 8 is out
topics[which(topics$topicId=="V9"),c("topicName", "topicWords", "topicTags")] = c("TF_graph", "tf,graph,graph_def","tensorflow,python") #low dominance
#topic 10 is out
#topic 11 is out
topics[which(topics$topicId=="V12"),c("topicName", "topicWords", "topicTags")] = c("Convergence_Determination", "train_accuraci,loss,learn_rate","softmax,covergence,nn")
topics[which(topics$topicId=="V13"),c("topicName", "topicWords", "topicTags")] = c("Deployment", "user,product,api","google-prediction,azure,api,web-services,firebase")
topics[which(topics$topicId=="V14"),c("topicName", "topicWords", "topicTags")] = c("Data_Prep", "nan,label,format","data-management,aggregation,input")
#topic 15 is out
topics[which(topics$topicId=="V16"),c("topicName", "topicWords", "topicTags")] = c("TF_debugging", "tf,sess_run,tf_variabl","tensorflow,iterable,tensor")
topics[which(topics$topicId=="V17"),c("topicName", "topicWords", "topicTags")] = c("TF_prog_err", "py_line,packag_tensorflow,run","tensorflow,django,ubuntu,low-memory,seq-to-seq")
topics[which(topics$topicId=="V18"),c("topicName", "topicWords", "topicTags")] = c("Model_Saving", "model,load,save","tensorflow-serving,google-cloud-functions")
# topic 19 is out
topics[which(topics$topicId=="V20"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Classification", "class,accuraci,confus_matrix","classification,precision-recall,analytics,predictive")
topics[which(topics$topicId=="V21"),c("topicName", "topicWords", "topicTags")] = c("Object_Detection", "object_detect,face,bound_box","image-segmentation,object-detection,opencv,image-processing,motion-detection,tracking,feature-extraction")
topics[which(topics$topicId=="V22"),c("topicName", "topicWords", "topicTags")] = c("Feature_Preprocessing", "featur,transform,split","pandas,feature-extraction,feature-selection")
topics[which(topics$topicId=="V23"),c("topicName", "topicWords", "topicTags")] = c("Model_Training", "train,sampl,fit","cross-validation,validation,gradient-descent")
topics[which(topics$topicId=="V24"),c("topicName", "topicWords", "topicTags")] = c("keras", "kera,model,input_shape","keras,conv-neural-network,deep-learning,neural-networks")
topics[which(topics$topicId=="V25"),c("topicName", "topicWords", "topicTags")] = c("Clustering", "cluster,distanc,,centroid","hierarchical-clustering,cluster-analysis,kmeans")
topics[which(topics$topicId=="V26"),c("topicName", "topicWords", "topicTags")] = c("TF_hardware", "tensorflow,gpu,cpu","multithreading,gpu,gensorflow-gpu")
topics[which(topics$topicId=="V27"),c("topicName", "topicWords", "topicTags")] = c("Evaluation_Regression", "regress,error,auc","lasso,linear-regression,glmnet,interpretation")
topics[which(topics$topicId=="V28"),c("topicName", "topicWords", "topicTags")] = c("NLP", "text,tweet,,senti","nlp,classification,stanford-nlp,opennlp")
topics[which(topics$topicId=="V29"),c("topicName", "topicWords", "topicTags")] = c("Preprocessing_images", "img,mask,convert","pickle,cnn,feature-extration,unit,image-processing")
#topic 30 is out
#assigning overall topic label
topics[which(topics$topicId=="V4" | topics$topicId=="V6" | topics$topicId=="V7" | topics$topicId=="V9"|
topics$topicId=="V13"|topics$topicId=="V14"|topics$topicId=="V15"|topics$topicId=="V16"| topics$topicId=="V2" |
topics$topicId=="V17" | topics$topicId=="V18" | topics$topicId=="V22" | topics$topicId=="V26" | topics$topicId=="V29" | topics$topicId=="V24"),"topicClass"]  = "ML Library"
topics[which(topics$topicId=="V5" | topics$topicId=="V12" | topics$topicId=="V20" | topics$topicId=="V21" | topics$topicId=="V23"| topics$topicId=="V27"|topics$topicId=="V28"),"topicClass"]  = "ML Concept"
topics[which(topics$topicId=="V1" | topics$topicId=="V3" | topics$topicId=="V25"),"topicClass"]  = "ML Algorithm"
#generating topic stat
for(i in 1:length(topiclist)){
topics[which(topics$topicId==topiclist[i]),"postCount"] = length(which(resultset$dominatingTopic==topiclist[i]))
topics[which(topics$topicId==topiclist[i]),"viewsCount"] = sum(resultset[which(resultset$dominatingTopic==topiclist[i]),c("ViewCount")])/sum(resultset[,c("ViewCount")])
topics[which(topics$topicId==topiclist[i]),"unanswered_topic"] = length(resultset[which(resultset$dominatingTopic==topiclist[i] & resultset$AcceptedAnswerId=="None"),c("AcceptedAnswerId")]) /length(resultset[which(resultset$dominatingTopic==topiclist[i]),c("AcceptedAnswerId")])
}
#creating a columns for plotting purposes
topics[,"unanswered_topic_factor"] = "Low % Unanswered Questions (< Median)"
topics[which(topics$unanswered_topic>median(topics$unanswered_topic)),"unanswered_topic_factor"] = "High % Unanswered Questions (> Median)"
topics = topics[order(topics$unanswered_topic),]
topics[,"plotorder"] = 1:k
topics[which(topics$topicName=="NLP"),"plotorder"] = 1
topics[which(topics$topicName=="TF_debugging"),"plotorder"] = 2
topics[which(topics$topicName=="Evaluation_Classification"),"plotorder"] = 3
topics[which(topics$topicName=="Convergence_Determination"),"plotorder"] = 4
topics[which(topics$topicName=="Visualization"),"plotorder"] = 5
topics[which(topics$topicName=="Decision_Tree"),"plotorder"] = 6
topics[which(topics$topicName=="Optimization"),"plotorder"] = 8
topics[which(topics$topicName=="keras"),"plotorder"] = 7
topics[which(topics$topicName=="Clustering"),"plotorder"] = 10
topics[which(topics$topicName=="Neural_Networks"),"plotorder"] = 11
topics[which(topics$topicName=="Data_Prep"),"plotorder"] = 12
topics[which(topics$topicName=="Evaluation_Regression"),"plotorder"] = 13
topics[which(topics$topicName=="Feature_Preprocessing"),"plotorder"] = 14
topics[which(topics$topicName=="Environment_Setup"),"plotorder"] = 19
topics[which(topics$topicName=="Data_Prep2"),"plotorder"] = 20
topics[which(topics$topicName=="Preprocessing_images"),"plotorder"] = 21
topics[which(topics$topicName=="Object_Detection"),"plotorder"] = 22
topics[which(topics$topicName=="Applied_NN"),"plotorder"] = 23
topics[which(topics$topicName=="Model_Training"),"plotorder"] = 24
topics[which(topics$topicName=="TF_hardware"),"plotorder"] = 25
topics[which(topics$topicName=="TF_Installation"),"plotorder"] = 26
topics[which(topics$topicName=="TF_graph"),"plotorder"] = 30
topics[which(topics$topicName=="TF_prog_err"),"plotorder"] = 29
topics[which(topics$topicName=="Model_Saving"),"plotorder"] = 28
topics[which(topics$topicName=="Deployment"),"plotorder"] = 27
## PLOTTING Figure 7
myplot = ggplot(data=topics, aes(x= reorder(topicWords,plotorder)   , y = postCount, fill=topicClass))+
geom_bar(stat="identity",colour = "black")+scale_fill_brewer(palette="Oranges")+
geom_label(aes(label =topicName,fontface=2),position = position_stack(vjust = 1),size =5.5,fill = 'white', colour = 'black')+
labs(title="", x="Three-word Topics",y="#Questions") +
theme_bw() +theme(panel.grid.major = element_blank())+
theme(legend.title=element_blank())+ theme(legend.position="top") + theme(legend.key.width=unit(1.5,"cm")) +
theme(legend.spacing.x = unit(0.5,"cm"), legend.text = element_text(size=20, face = "bold", color = "black") ) +
theme(text = element_text(size=30), axis.text.x = element_text(size=20,face = "bold"), axis.text.y = element_text(size=35))+
theme(axis.text.x = element_text(angle = 30, hjust = 1))
myplot
## PLOTTING Figure 8
library(ggplot2)
library(ggExtra)
p=ggplot(topics, aes(x=unanswered_topic, y=viewsCount, color=unanswered_topic_factor, label=topicName)) +
geom_point() +    geom_label(aes(label =topicName,fontface=2),position = position_stack(vjust = 1),size =8,fill = 'white', colour = 'black') + xlim(0.52,0.68) + labs(title="", x="Difficulty (% no accepted answer)",y="Popularity (% views)") +
geom_hline(aes(yintercept = 0.050)) + geom_vline(aes(xintercept = 0.60)) +
theme(panel.background = element_blank())+
theme(legend.position="none") +
theme(text = element_text(size=30,face = "bold"), axis.text.x = element_text(size=30,face = "bold"), axis.text.y = element_text(size=30,face = "bold"))
p
